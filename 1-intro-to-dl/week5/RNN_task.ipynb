{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "ihxkkKjvuei0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "UKSXofk1uk9n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "6626ef4a-3677-4085-b84f-2fa26152434a"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2019-03-17 17:05:15--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2019-03-17 17:05:15 (64.3 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "8QuPHOKVuei2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1e19c812-6a78-46fb-b997-4d18e12e791a"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.13.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EDdaKFf9uei6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "7rDLStspuei7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "Ed5Mohvsuei-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a2315e9a-abbd-4f15-e659-d52cfc3597c6"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "# print one by every 1000 examples\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "W-sWkdOAuejA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "9cdbacdc-52f2-4ac9-aa52-d41a04883ebc"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "mvuwcjlguejD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "YKTEihRJuejE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bde57443-8b23-4845-b634-61d8754065b4"
      },
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens = []\n",
        "\n",
        "for name in names:\n",
        "  for x in list(name):\n",
        "    tokens.append(x)\n",
        "tokens = list(set(tokens))\n",
        "tokens.append(pad_token)\n",
        "\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6M7MS1WluejH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "lRhiMKkouejI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07b902e6-d25b-4db5-de74-cf2edf266e16"
      },
      "cell_type": "code",
      "source": [
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "token_to_id = {}\n",
        "\n",
        "for idx, token in enumerate(tokens):\n",
        "  token_to_id[token] = idx\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
        "\n",
        "for i in range(n_tokens):\n",
        "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
        "\n",
        "print(\"Seems alright!\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seems alright!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "KcqroQJhuejM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Very pretty function!\n",
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    # First pad the sepueces with pad_tokens\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "  \n",
        "    '''\n",
        "    For each name, get the id for each char. Use map(dict.get, list)\n",
        "    ''' \n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "l7BulC-AuejP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "8744811d-6db3-4b24-ad07-3a1189394f60"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[45 51 46  2  9  2  1 47 55]\n",
            " [45 35 47 53 39 52 55 55 55]\n",
            " [45  6 39 24 38 38 24  1 55]\n",
            " [45 35 24 53 23  2 50 50  1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "V9fxvg1juejT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "z-H-n3ybuejU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "IP-esNL5uejX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "### YOUR CODE HERE\n",
        "get_h_next = Dense(rnn_num_units, activation=\"tanh\")\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "### YOUR CODE HERE\n",
        "get_probas = Dense(n_tokens, activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pW8vn6nDuejZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "mWeU_YNluejZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    ### YOUR CODE HERE\n",
        "    x_and_h = concatenate([x_t_emb, h_t])\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    ### YOUR CODE HERE\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    ### YOUR CODE HERE\n",
        "    output_probas = get_probas(h_next)\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2BURWR5uejc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "rx99JNfVuejd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s3J0h3xBuejf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "P8Vi8KCQuejg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NQj-f1oRueji",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "3xq_Z1fuuejm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "### YOUR CODE HERE\n",
        "loss = -tf.reduce_mean(answers_matrix * tf.log(predictions_matrix))\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ALlZ2ZRMuejp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "NrBQsoNjuejq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "990f2b84-3feb-4289-a05b-8a1906bef8af"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "_yS7h2Jyuejv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "E4IoRDNtuejw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "FrJAWeeruejy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "fHmBIl8_uej1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7ca92562-31c8-4ed1-9dbe-c51543cee509"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Bney\n",
            " Laretla\n",
            " Karan\n",
            " Carbis\n",
            " Telsi\n",
            " Keuskee\n",
            " Becy\n",
            " Golirh\n",
            " Dalheem\n",
            " Morpont\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "xDOonu_8uej3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "e7bc15c6-ae3b-4b5b-e104-cddca863f311"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpe\n",
            " Trumparnin\n",
            " Trumptin\n",
            " Trumpil\n",
            " Trumpal\n",
            " Trumpien\n",
            " Trumpisa\n",
            " Trumpgie\n",
            " Trumpiledra\n",
            " Trumpal\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "siz8aU3nuej6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "ed2yIKTRuej7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"iwe9U4KKonPStlpu\"\n",
        "COURSERA_EMAIL = \"y2469wan@edu.uwaterloo.ca\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "Mg7ACFPmuej_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "72f7ac6a-d477-4bba-f2e3-71457dfbfc50"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "flir9HCKuekC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "wlxXUnsWuekC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "1kcIJLftuekE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "67c1c2df-4a6f-498a-8fc8-9205a77fed20"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From <ipython-input-31-5f3812e903bf>:17: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WU_aWEsNuekI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "5Agi_4qouekJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7936ad36-13c7-45d8-80cb-f5da9898b924"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "OklQW6FuuekM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "260921a9-324d-4f18-9017-566e8f131a21"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-33-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9BTXIYtJvR36",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}